---
title: "Procesamiento 3"
author: "Andres Felipe Beltran"
date: "5/11/2021"
output:
   prettydoc::html_pretty:
     theme: cayman
---

En este documento se presenta el flujo de trabajo utilizado para procesar los espectros compartidos en las carpetas `3_T 50` y `3 SST50`

Primero, creamos una lista con los nombres de los archivos contenidos en esta carpeta, para poder importarlos a `R`:

```{r}
nombres <- list.files(, pattern = 'CSV')
nombres
```

Revisamos si los triplicados estan completos:

```{r}
(length(nombres)-1)/3
```
Hasta el momento, hay un espectro repetido:

```{r}
nombres[46]
```

Vamos a continuar sin este espectro por el momento:

```{r}
nombres <- nombres[-46]
```

Procedemos a utilizr la función `read.csv` para leer los archivos `.CSV` y crear objetos dentro de R que van a contener su información.

Ya que `nombres` es una lista, podemos utilizar la función de ciclo `lapply` para aplicar de manera iterativa la función `read.csv` a todos los elementos de la lista `nombres`, guardando el resultado de cada iteración en cada elemento de la lista `data`.


```{r}
data <- lapply(nombres, read.csv, header = FALSE)
```

`data` es un objeto de clase `list` que contiene en cada posición, un `data.frame` con la información de los `.csv`. Es decir, una columna con los números de onda, y otra con las absorbancias:

```{r}
str(data[[1]])
```
En este punto, podemos guardar la información de los números de onda en un objeto llamado `wavenumber`

```{r}
wavenumber <- data[[1]][,1]
```

En el chunk anterior guardamos lo que hay en la primera columna `[,1]` del primer elemento de `data`: `data[[1]]` 

Ahora, podemos volver a aplicar la función `lapply`, en este caso a la lista `data` para extraer solo la segunda columna, que es la que nos interesa para construir nuestro data.frame para análisis quimiométrico.

```{r}
data2 <- lapply(data, '[', 2)
```

Al usar la función `lapply`, de nuevo creamos una lista. podemos convertir la lista `data2` en un `data.frame` mediante la función `as.data.frame`.

```{r}
data2 <- as.data.frame(data2)
dim(data2)
names(data2) <- nombres
```
Ahora tenemos un `data.frame` con 1869 filas y 120 columnas, los triplicados de 40 muestras.

Ahora podemos proceder a crear la transpuesta de este data.frame utilizando la función `t()`:

```{r}
datat <- t(data2)
```

`datat` es un objeto de clase `matrix`,  en cuyos `rownames` contiene los nombres de las muestras, como vienen en los nombres de los archivos `.CSV`.

Ahora, recuperamos la información almacenada en el objeto `wavenumber` para nombrar las columnas, o variables del objeto `datat`

```{r}
colnames(datat) <- wavenumber
```

Ahora, para encontrar los espectros a los cuales les vamos a calcular el promedio, utilizamos una matriz de búsqueda, conteniendo los niveles que diferencian las muestras, en este caso son:

* Zona de muestreo: `UF1` `UF2` `UF3` `UF4` `UF5` y `LF1` `LF2` `LF3` `LF4` `LF5`.
* tiempo de molienda: `A` y `B`.
* con o sin solución salina `SS` y ` `.

```{r}
set.seed(0)

searchGrid <- expand.grid(Sampling = c('UF1',
                                       'UF2',
                                       'UF3',
                                       'UF4',
                                       'UF5',
                                       'LF1',
                                       'LF2',
                                       'LF3',
                                       'LF4',
                                       'LF5'),
                          millingTime = c('A',
                                          'B'),
                          brine = c('SS',
                                    ''))

# knitr::kable(searchGrid)
```

En la matriz `searchGrid` tenemos un total de 40 combinaciones para los nombres de las muestras, según las distintas variaciones de los tratamientos. 

Vamos a utilizar esta matriz, para buscar entre todos los nombres de todos los espectros, y encontrar los tres triplicados para cada variación del experimento:

Primero, vamos a crear un vector que va a contener los nuevos nombres que identifican cada variación del experimento:

```{r}
rownames.prom <- character(40)
```

Luego, mediante un ciclo `for` podemos guardar en cada posición de `rownames.prom` la unión de las tres variables para cada experimento:

```{r}
for(i in 1:40){
  
  rownames.prom[i] <- paste(searchGrid[i,1],
      searchGrid[i,2],
      searchGrid[i,3])
}
rownames.prom
```

Ahora, creamos la matriz en la cual vamos a guardar los resultados el promedio de cada triplicado:

```{r}
prom <- matrix(,
               ncol = ncol(datat),
               nrow = nrow(datat)/3)
```

Ahora, vamos a crear una lista llamada `index`. En esta lista, vamos a guardar las 3 posiciones dentro de la lista `nombres` que van a coincidir con las expresiones regulares dictadas por `searchGrid` para cada variación del experimento. 

Por ejemplo, para `UF1 A SS`,  la posición correspondiente en la lista `index` va a contener 3 elementos que nos dicen las posiciones para los espectros  `UF1 A SS 1`, `UF1 A SS 2`, y `UF1 A SS 3` dentro de los nombres de las filas de `datat`.

```{r}
index <- vector('list',40)
```

Ahora, vamos a utilizar una función de búsqueda, anidada con una función de comparación.

* `grepl` función de búsqueda que utiliza expresiones regulares (variables según la búsqueda) junto con caracteres (provenientes de `searchGrid`) como input
* `which` función de comparación que nos dice si se cumple o no una condición, pasa como argumento el output de `grepl` que nos dice si sí o no coincide el elemento en cuestión con el criterio de búsqueda.

```{r }
for(i in 1:40){
  
  index[[i]] <- c(
                  which(
                         grepl(
                                paste0('(?=.*',
                                      as.character(searchGrid[i,1]),
                                      ')(?=.*',
                                      as.character(searchGrid[i,2]),
                                      ')(?=.*',
                                       as.character(searchGrid[i,3]),
                                      ')'
                                  
                                       ),
                rownames(datat), perl = T              )
    
                       )
                  )
}
```

podemos confirmar los resultados antes de calcular. Por ejemplo, para la primera fila de `searchGrid` :

```{r}
searchGrid[1,]
```
Ya tenemos ubicados los espectros que corresponden a esta combinación:

```{r}
index[[1]]
```
confirmando en los nombres de las muestras de `datat`:
```{r}
rownames(datat)[index[[1]]]
```

Corresponde a los tres triplicados de la muestra `UF1`, la cual tuvo un tiempo de molienda de 2 a 4 minutos, y una extracción con solución salina.


Podemos proceder a calcular los promedios:

```{r}
for(j in 1:length(colnames(datat))){
  
for(i in 1:40){

prom[i,j] <- mean(c(datat[index[[i]][1],j],
                    datat[index[[i]][2],j],
                    datat[index[[i]][3],j]
                      ) )
}
}

rownames(prom) <- rownames.prom
colnames(prom) <- wavenumber
```


Una vez calculados, podemos graficar los promedios:

Podemos diferenciar los espectros de las muestras a las cuales se les realizo la extracción con solución salina mediante una revisión

```{r}
NaCl <- vector('character', length(rownames(prom)))

for(i in 1:40){
  
 if(grepl('SS', rownames(prom)[i],perl =T)){NaCl[i]<- 'blue'}
  else{NaCl[i]<- 'black'}
  
}


indexSS <- vector('logical',40)

 indexSS<-which(grepl('SS', rownames(prom),perl =T))
  


```


```{r}
for(i in 1:40){
  plot(wavenumber,
      prom[i,],
       xlab = 'wave number cm-1',
       ylab = 'absorbance a.u.',
       xlim = c(3900,400),
       ylim = c(0,0.12),
       type = 'l',
       col = NaCl[i])
  par(new = T)

  
}
```

Podemos seleccionar este rango , de 1700 a 400 $cm^{-1}$ creando un nuevo objeto para los promedios y para los números de ondaÑ

```{r}
colnames(prom)[c(1,676)]
```
```{r}
Rango1 <- prom[,1:676]
wn.Rango1 <- wavenumber[1:676]
```


Para eliminar la variabilidad por ruido instrumental, podemos calcular y restar la línea base para cada uno de los promedios, utilizando el método `rubberband` disponible en el paquete de R `hyperSpec`, desarrollado para quimiometría aplicada a imágenes hiper-espectrales.



```{r message=FALSE}
library(hyperSpec)
spc <- new('hyperSpec', spc = Rango1, wavelength = wn.Rango1)
bend <- 0.1 * wl.eval (spc, function (x) x^6+x^5+x^4+x^3+x^2, normalize.wl=normalize01)

bl <- spc.rubberband (spc+bend, noise = 1e-4, df=20)-bend
suma <- spc+bend
spc3 <- spc - bl

plot(spc, wl.reverse = TRUE)
plot(bl, add=TRUE, col=2,wl.reverse = TRUE)

plot(suma,wl.reverse = TRUE)
plot(bend, add=TRUE, col=2,wl.reverse = TRUE)
plot(spc3,wl.reverse = TRUE)

corregido <- as.data.frame(spc3[1:31])
corregido2 <- as.data.frame(corregido[,1])
```

En el procedimiento de corrección de línea base, observamos que uno de los espectros promedio tiene una deriva instrumental mucho más notoria que los demás, podemos preguntarle a R cual de los espectros presenta estos valores de absorbancia tan altos:

```{r}
which(prom[,1]>0.2)
```
Sabiendo que es el elemento en la lista de promedios número 23, podemos preguntar a `index` a partir de que espectros se calculó el promedio, y graficar los tres para ver si los tres presentan el mismo comportamiento.

```{r}
index[[23]]
rownames(prom)[23]
```
```{r}
rownames(datat)[c(22,23,24)]
```
```{r}
for(i in 1:3){
  plot(wavenumber,
       datat[index[[23]][i],],
        xlab = 'wave number cm-1',
       ylab = 'absorbance a.u.',
       xlim = c(1700,400),
       ylim = c(0,1),
       type = 'l')
  par(new = T)
       
    
  
  
}
```

Con esto podemos confirmar que la desviación por deriva instrumental no se debe a una de las replicas, si no a la muestra `UF3 A`. A pesar de que con el tratamiento de corrección de línea base se elimina este problema, es importante confirmar cual es la muestra que presenta esta deriva.

# Análisis exploratorio




```{r}
pca.bl <- prcomp(corregido2, scale =F, center = T)
vp.bl <- (pca.bl$sdev)^2
varianza.bl <- round(vp.bl/sum(vp.bl)*100, 2)
varianza.bl
```
```{r}
library(mdatools)
mdaPCA <-pca(corregido2, 5, center = TRUE, scale = TRUE)
summary(mdaPCA)
win.graph()
plotScores(mdaPCA$res$cal, show.labels = TRUE)
```
Ya que mediante PCA para estas muestras en específico, no se obserban agrupamientos notorios, podemos exportar estos resultados y compararlos con los resultados de los experimentos anteriores:

```{r}
write.table(prom, 'SSexp.txt' , sep = '\t')
```

